{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18b35272",
   "metadata": {},
   "source": [
    "# Test de Word/Sentence embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82210a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0ca0d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0e6826c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Title', 'Body', 'Tags', 'title_bow_lem', 'body_bow_lem',\n",
       "       'title_bow_stem', 'body_bow_stem'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e527a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in ['Tags', 'title_bow_lem', 'body_bow_lem', 'title_bow_stem', 'body_bow_stem']:\n",
    "    data[c] = data[c].transform(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "285074fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "      <th>title_bow_lem</th>\n",
       "      <th>body_bow_lem</th>\n",
       "      <th>title_bow_stem</th>\n",
       "      <th>body_bow_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9614</th>\n",
       "      <td>image resources for ios</td>\n",
       "      <td>i m probably missing something obvious here  y...</td>\n",
       "      <td>[c, objective, xcode, ios]</td>\n",
       "      <td>[image]</td>\n",
       "      <td>[project, image, someimage, png, someimage, pn...</td>\n",
       "      <td>[imag]</td>\n",
       "      <td>[project, imag, someimag, png, someimag, png, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20844</th>\n",
       "      <td>why  response expectedcontentlength  always re...</td>\n",
       "      <td>i have this code  download_size is nsinteger ...</td>\n",
       "      <td>[iphone, ios]</td>\n",
       "      <td>[response, expectedcontentlength]</td>\n",
       "      <td>[download_size, someone, use, effect, help]</td>\n",
       "      <td>[respons, expectedcontentlength]</td>\n",
       "      <td>[download_s, someon, use, effect, help]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>why would you ever want to allocate memory on ...</td>\n",
       "      <td>possible duplicate  when is it best to use a ...</td>\n",
       "      <td>[c, memory]</td>\n",
       "      <td>[memory, heap, stack]</td>\n",
       "      <td>[duplicate, stack, heap, vice, versa, heap, v,...</td>\n",
       "      <td>[memori, heap, stack]</td>\n",
       "      <td>[duplic, stack, heap, vice, versa, heap, vs, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16732</th>\n",
       "      <td>what is the best standard style for a tostring...</td>\n",
       "      <td>we have a lot of objects for which we like to ...</td>\n",
       "      <td>[java, javascript, php]</td>\n",
       "      <td>[style, tostring, implementation]</td>\n",
       "      <td>[lot, output, standard, practice, style, case,...</td>\n",
       "      <td>[style, tostr, implement]</td>\n",
       "      <td>[lot, output, standard, practic, style, case, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19418</th>\n",
       "      <td>sql server invalid column name after adding ne...</td>\n",
       "      <td>i just added an identity column to an existing...</td>\n",
       "      <td>[server, sql]</td>\n",
       "      <td>[sql, server, column, name, column]</td>\n",
       "      <td>[identity, column, table, designer, table, que...</td>\n",
       "      <td>[sql, server, column, name, column]</td>\n",
       "      <td>[ident, column, tabl, design, tabl, queri, que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7351</th>\n",
       "      <td>removing trailing newline character from fgets...</td>\n",
       "      <td>i am trying to get some data from the user and...</td>\n",
       "      <td>[c, string]</td>\n",
       "      <td>[character]</td>\n",
       "      <td>[user, function, gcc, character, end, string]</td>\n",
       "      <td>[charact]</td>\n",
       "      <td>[user, function, gcc, charact, end, string]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20731</th>\n",
       "      <td>what is an  internal address  in java</td>\n",
       "      <td>in the javadoc for object hashcode   it states...</td>\n",
       "      <td>[java, memory]</td>\n",
       "      <td>[address, java]</td>\n",
       "      <td>[javadoc, hashcode, hashcode, method, class, a...</td>\n",
       "      <td>[address, java]</td>\n",
       "      <td>[javadoc, hashcod, hashcod, method, class, add...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12193</th>\n",
       "      <td>detect carrier connection type  3g   edge   gprs</td>\n",
       "      <td>how can i get the type of connection of a carr...</td>\n",
       "      <td>[c, objective, iphone, ios]</td>\n",
       "      <td>[detect, carrier, connection, type, edge, gprs]</td>\n",
       "      <td>[type, connection, carrier, network, connectio...</td>\n",
       "      <td>[detect, carrier, connect, type, edg, gprs]</td>\n",
       "      <td>[type, connect, carrier, network, connect, cla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2568</th>\n",
       "      <td>how to enable disable wifi from an application</td>\n",
       "      <td>i want to enable disable wifi from my android ...</td>\n",
       "      <td>[android, java]</td>\n",
       "      <td>[wifi, application]</td>\n",
       "      <td>[wifi, application]</td>\n",
       "      <td>[wifi, applic]</td>\n",
       "      <td>[wifi, applic]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14480</th>\n",
       "      <td>spring rest   create zip file and send it to t...</td>\n",
       "      <td>i want to create a zip file that contains my a...</td>\n",
       "      <td>[java, spring]</td>\n",
       "      <td>[spring, rest, create, zip, file, client]</td>\n",
       "      <td>[zip, file, backend, file, user, answer, solut...</td>\n",
       "      <td>[spring, rest, creat, zip, file, client]</td>\n",
       "      <td>[zip, file, backend, file, user, answer, solut...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24728 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Title  \\\n",
       "9614                             image resources for ios   \n",
       "20844  why  response expectedcontentlength  always re...   \n",
       "1771   why would you ever want to allocate memory on ...   \n",
       "16732  what is the best standard style for a tostring...   \n",
       "19418  sql server invalid column name after adding ne...   \n",
       "...                                                  ...   \n",
       "7351   removing trailing newline character from fgets...   \n",
       "20731             what is an  internal address  in java    \n",
       "12193  detect carrier connection type  3g   edge   gprs    \n",
       "2568     how to enable disable wifi from an application    \n",
       "14480  spring rest   create zip file and send it to t...   \n",
       "\n",
       "                                                    Body  \\\n",
       "9614   i m probably missing something obvious here  y...   \n",
       "20844   i have this code  download_size is nsinteger ...   \n",
       "1771    possible duplicate  when is it best to use a ...   \n",
       "16732  we have a lot of objects for which we like to ...   \n",
       "19418  i just added an identity column to an existing...   \n",
       "...                                                  ...   \n",
       "7351   i am trying to get some data from the user and...   \n",
       "20731  in the javadoc for object hashcode   it states...   \n",
       "12193  how can i get the type of connection of a carr...   \n",
       "2568   i want to enable disable wifi from my android ...   \n",
       "14480  i want to create a zip file that contains my a...   \n",
       "\n",
       "                              Tags  \\\n",
       "9614    [c, objective, xcode, ios]   \n",
       "20844                [iphone, ios]   \n",
       "1771                   [c, memory]   \n",
       "16732      [java, javascript, php]   \n",
       "19418                [server, sql]   \n",
       "...                            ...   \n",
       "7351                   [c, string]   \n",
       "20731               [java, memory]   \n",
       "12193  [c, objective, iphone, ios]   \n",
       "2568               [android, java]   \n",
       "14480               [java, spring]   \n",
       "\n",
       "                                         title_bow_lem  \\\n",
       "9614                                           [image]   \n",
       "20844                [response, expectedcontentlength]   \n",
       "1771                             [memory, heap, stack]   \n",
       "16732                [style, tostring, implementation]   \n",
       "19418              [sql, server, column, name, column]   \n",
       "...                                                ...   \n",
       "7351                                       [character]   \n",
       "20731                                  [address, java]   \n",
       "12193  [detect, carrier, connection, type, edge, gprs]   \n",
       "2568                               [wifi, application]   \n",
       "14480        [spring, rest, create, zip, file, client]   \n",
       "\n",
       "                                            body_bow_lem  \\\n",
       "9614   [project, image, someimage, png, someimage, pn...   \n",
       "20844        [download_size, someone, use, effect, help]   \n",
       "1771   [duplicate, stack, heap, vice, versa, heap, v,...   \n",
       "16732  [lot, output, standard, practice, style, case,...   \n",
       "19418  [identity, column, table, designer, table, que...   \n",
       "...                                                  ...   \n",
       "7351       [user, function, gcc, character, end, string]   \n",
       "20731  [javadoc, hashcode, hashcode, method, class, a...   \n",
       "12193  [type, connection, carrier, network, connectio...   \n",
       "2568                                 [wifi, application]   \n",
       "14480  [zip, file, backend, file, user, answer, solut...   \n",
       "\n",
       "                                    title_bow_stem  \\\n",
       "9614                                        [imag]   \n",
       "20844             [respons, expectedcontentlength]   \n",
       "1771                         [memori, heap, stack]   \n",
       "16732                    [style, tostr, implement]   \n",
       "19418          [sql, server, column, name, column]   \n",
       "...                                            ...   \n",
       "7351                                     [charact]   \n",
       "20731                              [address, java]   \n",
       "12193  [detect, carrier, connect, type, edg, gprs]   \n",
       "2568                                [wifi, applic]   \n",
       "14480     [spring, rest, creat, zip, file, client]   \n",
       "\n",
       "                                           body_bow_stem  \n",
       "9614   [project, imag, someimag, png, someimag, png, ...  \n",
       "20844            [download_s, someon, use, effect, help]  \n",
       "1771   [duplic, stack, heap, vice, versa, heap, vs, s...  \n",
       "16732  [lot, output, standard, practic, style, case, ...  \n",
       "19418  [ident, column, tabl, design, tabl, queri, que...  \n",
       "...                                                  ...  \n",
       "7351         [user, function, gcc, charact, end, string]  \n",
       "20731  [javadoc, hashcod, hashcod, method, class, add...  \n",
       "12193  [type, connect, carrier, network, connect, cla...  \n",
       "2568                                      [wifi, applic]  \n",
       "14480  [zip, file, backend, file, user, answer, solut...  \n",
       "\n",
       "[24728 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.sample(frac=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d61cf8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel = MultiLabelBinarizer()\n",
    "y = multilabel.fit_transform(data['Tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e025cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultats = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae1dca8",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc0493ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import metrics as kmetrics\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41c78c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['body_bow_lem'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26eccb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_size=300\n",
    "w2v_window=5\n",
    "w2v_min_count=1\n",
    "w2v_epochs=100\n",
    "maxlen = 755 # adapt to length of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6240ebd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = X.to_list()\n",
    "sentences = [gensim.utils.simple_preprocess(text) for text in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d34bbeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.Word2Vec(min_count=w2v_min_count, window=w2v_window,\n",
    "                                                vector_size=w2v_size,\n",
    "                                                seed=42,\n",
    "                                                workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f677228a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 20740\n",
      "Word2Vec trained\n"
     ]
    }
   ],
   "source": [
    "w2v_model.build_vocab(sentences)\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=w2v_epochs)\n",
    "model_vectors = w2v_model.wv\n",
    "w2v_words = model_vectors.index_to_key\n",
    "print(\"Vocabulary size: %i\" % len(w2v_words))\n",
    "print(\"Word2Vec trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12767f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit Tokenizer ...\n",
      "Number of unique words: 20741\n"
     ]
    }
   ],
   "source": [
    "# PrÃ©paration des sentences (tokenization)\n",
    "\n",
    "print(\"Fit Tokenizer ...\")\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "x_sentences = pad_sequences(tokenizer.texts_to_sequences(sentences),\n",
    "                                                     maxlen=maxlen,\n",
    "                                                     padding='post') \n",
    "                                                   \n",
    "num_words = len(tokenizer.word_index) + 1\n",
    "print(\"Number of unique words: %i\" % num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c1e1763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Embedding matrix ...\n",
      "Word embedding rate :  1.0\n",
      "Embedding matrix: (20741, 300)\n"
     ]
    }
   ],
   "source": [
    "# CrÃ©ation de la matrice d'embedding\n",
    "\n",
    "print(\"Create Embedding matrix ...\")\n",
    "w2v_size = 300\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((vocab_size, w2v_size))\n",
    "i=0\n",
    "j=0\n",
    "    \n",
    "for word, idx in word_index.items():\n",
    "    i +=1\n",
    "    if word in w2v_words:\n",
    "        j +=1\n",
    "        embedding_vector = model_vectors[word]\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[idx] = model_vectors[word]\n",
    "            \n",
    "word_rate = np.round(j/i,4)\n",
    "print(\"Word embedding rate : \", word_rate)\n",
    "print(\"Embedding matrix: %s\" % str(embedding_matrix.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8d39d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 755)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 755, 300)          6222300   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 300)               0         \n",
      "=================================================================\n",
      "Total params: 6,222,300\n",
      "Trainable params: 6,222,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# CrÃ©ation du modÃ¨le\n",
    "\n",
    "input=Input(shape=(len(x_sentences),maxlen),dtype='float64')\n",
    "word_input=Input(shape=(maxlen,),dtype='float64')  \n",
    "word_embedding=Embedding(input_dim=vocab_size,\n",
    "                         output_dim=w2v_size,\n",
    "                         weights = [embedding_matrix],\n",
    "                         input_length=maxlen)(word_input)\n",
    "word_vec=GlobalAveragePooling1D()(word_embedding)  \n",
    "embed_model = Model([word_input],word_vec)\n",
    "\n",
    "embed_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ccaf956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24728, 300)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = embed_model.predict(x_sentences)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b423215b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00068567,  0.02067879, -0.02711758, ...,  0.0087561 ,\n",
       "         0.00513197,  0.01007272],\n",
       "       [ 0.00019466, -0.0014124 , -0.00175916, ...,  0.00143563,\n",
       "         0.00022033,  0.00356921],\n",
       "       [-0.03191302, -0.00644214,  0.02830587, ...,  0.00451324,\n",
       "        -0.01391686,  0.0004166 ],\n",
       "       ...,\n",
       "       [ 0.00385025,  0.00931357, -0.02145561, ...,  0.00442275,\n",
       "         0.01606862,  0.00126241],\n",
       "       [ 0.00173325, -0.00148214, -0.0016219 , ...,  0.00146125,\n",
       "         0.00146609, -0.00124672],\n",
       "       [-0.00402275,  0.03207737, -0.02735896, ...,  0.02952688,\n",
       "         0.01471878,  0.0059419 ]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16e67f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(embeddings, y, random_state=21, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7156cf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "910a1e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10699639347410564"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(LinearSVC(), n_jobs=1)\n",
    "clf.fit(X_train, Y_train)\n",
    "pred = clf.predict(X_test)\n",
    "jaccard_score(Y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f96bac9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultats['Word2Vec'] = jaccard_score(Y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbbfd2c",
   "metadata": {},
   "source": [
    "# Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96370d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "2.6.0\n",
      "Num GPUs Available:  1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tensorflow.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe222c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2bab60de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de prÃ©paration des sentences\n",
    "def bert_inp_fct(sentences, bert_tokenizer, max_length) :\n",
    "    input_ids=[]\n",
    "    token_type_ids = []\n",
    "    attention_mask=[]\n",
    "    bert_inp_tot = []\n",
    "\n",
    "    for sent in sentences:\n",
    "        bert_inp = bert_tokenizer.encode_plus(sent,\n",
    "                                              add_special_tokens = True,\n",
    "                                              max_length = max_length,\n",
    "                                              padding='max_length',\n",
    "                                              return_attention_mask = True, \n",
    "                                              return_token_type_ids=True,\n",
    "                                              truncation=True,\n",
    "                                              return_tensors=\"tf\")\n",
    "    \n",
    "        input_ids.append(bert_inp['input_ids'][0])\n",
    "        token_type_ids.append(bert_inp['token_type_ids'][0])\n",
    "        attention_mask.append(bert_inp['attention_mask'][0])\n",
    "        bert_inp_tot.append((bert_inp['input_ids'][0], \n",
    "                             bert_inp['token_type_ids'][0], \n",
    "                             bert_inp['attention_mask'][0]))\n",
    "\n",
    "    input_ids = np.asarray(input_ids)\n",
    "    token_type_ids = np.asarray(token_type_ids)\n",
    "    attention_mask = np.array(attention_mask)\n",
    "    \n",
    "    return input_ids, token_type_ids, attention_mask, bert_inp_tot\n",
    "    \n",
    "\n",
    "# Fonction de crÃ©ation des features\n",
    "def feature_BERT_fct(model, model_type, sentences, max_length, b_size, mode='HF') :\n",
    "    batch_size = b_size\n",
    "    batch_size_pred = b_size\n",
    "    bert_tokenizer = transformers.AutoTokenizer.from_pretrained(model_type)\n",
    "    time1 = time.time()\n",
    "\n",
    "    for step in range(len(sentences)//batch_size) :\n",
    "        idx = step*batch_size\n",
    "        input_ids, token_type_ids, attention_mask, bert_inp_tot = bert_inp_fct(sentences[idx:idx+batch_size], \n",
    "                                                                      bert_tokenizer, max_length)\n",
    "        \n",
    "        if mode=='HF' :    # Bert HuggingFace\n",
    "            outputs = model.predict([input_ids, attention_mask, token_type_ids], batch_size=batch_size_pred)\n",
    "            last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "        if mode=='TFhub' : # Bert Tensorflow Hub\n",
    "            text_preprocessed = {\"input_word_ids\" : input_ids, \n",
    "                                 \"input_mask\" : attention_mask, \n",
    "                                 \"input_type_ids\" : token_type_ids}\n",
    "            outputs = model(text_preprocessed)\n",
    "            last_hidden_states = outputs['sequence_output']\n",
    "             \n",
    "        if step ==0 :\n",
    "            last_hidden_states_tot = last_hidden_states\n",
    "            last_hidden_states_tot_0 = last_hidden_states\n",
    "        else :\n",
    "            last_hidden_states_tot = np.concatenate((last_hidden_states_tot,last_hidden_states))\n",
    "    \n",
    "    features_bert = np.array(last_hidden_states_tot).mean(axis=1)\n",
    "    \n",
    "    time2 = np.round(time.time() - time1,0)\n",
    "    print(\"temps traitement : \", time2)\n",
    "     \n",
    "    return features_bert, last_hidden_states_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23542a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "max_length = 64\n",
    "batch_size = 10\n",
    "model_type = 'bert-base-uncased'\n",
    "model = transformers.TFAutoModel.from_pretrained(model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "172e00ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23cf35f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = X['Body'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fddd77a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temps traitement :  28.0\n"
     ]
    }
   ],
   "source": [
    "# CrÃ©ation des features\n",
    "\n",
    "features_bert, last_hidden_states_tot = feature_BERT_fct(model, model_type, sentences, \n",
    "                                                         max_length, batch_size, mode='HF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c0406c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 768)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_bert.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02bd3aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.08041111, -0.00679683,  0.645215  , ..., -0.13352282,\n",
       "         0.02891598,  0.04615709],\n",
       "       [-0.03140354, -0.09737708,  0.53651834, ..., -0.2158382 ,\n",
       "        -0.09667631,  0.11912355],\n",
       "       [-0.29708138,  0.05941759, -0.04106521, ..., -0.06608517,\n",
       "         0.12023851,  0.22784819],\n",
       "       ...,\n",
       "       [-0.03171147, -0.23251066,  0.30946395, ..., -0.36356553,\n",
       "         0.05622838, -0.00628305],\n",
       "       [-0.24331787, -0.2569276 ,  0.01086113, ..., -0.33381334,\n",
       "        -0.15886006,  0.32918283],\n",
       "       [-0.30160648,  0.21060966,  0.15644309, ..., -0.39124644,\n",
       "        -0.11557137,  0.31652117]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2427749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(features_bert, y[:2000], random_state=21, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6742775",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.16368632943420716"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(LinearSVC(), n_jobs=1)\n",
    "clf.fit(X_train, Y_train)\n",
    "pred = clf.predict(X_test)\n",
    "jaccard_score(Y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "312400a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultats['Bert'] = jaccard_score(Y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f19ec1",
   "metadata": {},
   "source": [
    "## Sur les titres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1fd78ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "max_length = 64\n",
    "batch_size = 10\n",
    "model_type = 'bert-base-uncased'\n",
    "model = transformers.TFAutoModel.from_pretrained(model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1cb7c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = data['Title'].iloc[:3000].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7ef5d0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temps traitement :  47.0\n"
     ]
    }
   ],
   "source": [
    "# CrÃ©ation des features\n",
    "\n",
    "features_bert, last_hidden_states_tot = feature_BERT_fct(model, model_type, sentences, \n",
    "                                                         max_length, batch_size, mode='HF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0668f4ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 768)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_bert.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be388b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.11041918, -0.28854597,  0.24364178, ..., -0.17264582,\n",
       "        -0.21411662,  0.11876289],\n",
       "       [-0.31735778, -0.05406343,  0.4588824 , ..., -0.13966443,\n",
       "         0.063547  ,  0.25379562],\n",
       "       [-0.06042207, -0.03452685, -0.13640599, ...,  0.06004938,\n",
       "        -0.06353816,  0.20839533],\n",
       "       ...,\n",
       "       [-0.0997923 , -0.33459848,  0.06694856, ..., -0.01030366,\n",
       "         0.27915046,  0.22758228],\n",
       "       [-0.12001015, -0.43744138,  0.09285793, ..., -0.29207155,\n",
       "         0.10852643,  0.10941215],\n",
       "       [-0.3182044 , -0.23519686, -0.09940531, ..., -0.10990528,\n",
       "         0.25867304,  0.09447138]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eee537f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(features_bert, y[:3000], random_state=21, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5860c034",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tony.mathieux\\anaconda3\\envs\\transformers\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2139875046952236"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(LinearSVC(), n_jobs=1)\n",
    "clf.fit(X_train, Y_train)\n",
    "pred = clf.predict(X_test)\n",
    "jaccard_score(Y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6b0c940a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultats['Bert_sur_les_titres'] = jaccard_score(Y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b74374",
   "metadata": {},
   "source": [
    "# USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8c2c36b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d7ee620d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_USE_fct(sentences, b_size) :\n",
    "    batch_size = b_size\n",
    "    time1 = time.time()\n",
    "\n",
    "    for step in range(len(sentences)//batch_size) :\n",
    "        idx = step*batch_size\n",
    "        feat = embed(sentences[idx:idx+batch_size])\n",
    "\n",
    "        if step ==0 :\n",
    "            features = feat\n",
    "        else :\n",
    "            features = np.concatenate((features,feat))\n",
    "\n",
    "    time2 = np.round(time.time() - time1,0)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "24eb9f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "885e4123",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "658a4c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:2000]\n",
    "sentences = X['Body'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "84476b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_USE = feature_USE_fct(sentences, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8dd93cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 512)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_USE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bc45a54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(features_USE, y[:2000], random_state=21, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c09acbf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28434121425943565"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(LinearSVC(), n_jobs=1)\n",
    "clf.fit(X_train, Y_train)\n",
    "pred = clf.predict(X_test)\n",
    "jaccard_score(Y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0a3f16f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultats['USE'] = jaccard_score(Y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e590abd7",
   "metadata": {},
   "source": [
    "### Sur les titres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "de4421f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = data['Title'].iloc[:4000].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e639a67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_USE = feature_USE_fct(sentences, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5b1326bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(features_USE, y[:4000], random_state=21, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7fa7e04b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3591963055297009"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(LinearSVC(), n_jobs=1)\n",
    "clf.fit(X_train, Y_train)\n",
    "pred = clf.predict(X_test)\n",
    "jaccard_score(Y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d27dba07",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultats['USE_titres'] = jaccard_score(Y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "673c05b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Word2Vec': 0.10699639347410564,\n",
       " 'Bert': 0.16368632943420716,\n",
       " 'Bert_sur_les_titres': 0.2139875046952236,\n",
       " 'USE': 0.28434121425943565,\n",
       " 'USE_titres': 0.3591963055297009}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78fb987",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
